{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip /gdrive/MyDrive/COVID-19_Radiography_Database_old.zip -d ./content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import tqdm\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _min_max_scaling(img):\n",
    "    return (img-np.min(img)) / (np.max(img)-np.min(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './content/COVID-19_Radiography_Dataset/COVID/'\n",
    "covid_images = sorted(glob.glob(path + '*.png'))\n",
    "\n",
    "idx = random.randint(0, len(covid_images))\n",
    "img = cv2.imread(covid_images[idx])\n",
    "print(\"image min value : \",img.min())\n",
    "print(\"image max value : \",img.max())\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.hist(img.flatten())\n",
    "plt.show()\n",
    "    \n",
    "img = cv2.imread(covid_images[idx])\n",
    "img = _min_max_scaling(img)\n",
    "print(\"image min value : \",img.min())\n",
    "print(\"image max value : \",img.max())\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.hist(img.flatten())\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './content/COVID-19_Radiography_Dataset/COVID/'\n",
    "covid_images = sorted(glob.glob(path + '*.png'))\n",
    "\n",
    "idx = random.randint(0, len(covid_images))\n",
    "img = cv2.imread(covid_images[idx])\n",
    "img = _min_max_scaling(img)\n",
    "print(\"image min value : \",img.min())\n",
    "print(\"image max value : \",img.max())\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.hist(img.flatten())\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './content/COVID-19_Radiography_Dataset/Normal/'\n",
    "normal_images = sorted(glob.glob(path + '*.png'))\n",
    "\n",
    "idx = random.randint(0, len(normal_images))\n",
    "img = cv2.imread(normal_images[idx])\n",
    "print(\"image min value : \",img.min())\n",
    "print(\"image max value : \",img.max())\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.hist(img.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './content/COVID-19_Radiography_Dataset/Viral Pneumonia/'\n",
    "pneumonia_images = sorted(glob.glob(path + '*.png'))\n",
    "\n",
    "idx = random.randint(0, len(pneumonia_images))\n",
    "img = cv2.imread(pneumonia_images[idx])\n",
    "print(\"image min value : \",img.min())\n",
    "print(\"image max value : \",img.max())\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.hist(img.flatten())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './content/COVID-19_Radiography_Dataset/'\n",
    "normal_images = sorted(glob.glob(path +'Normal/' +  '*.png'))\n",
    "covid_images = sorted(glob.glob(path + 'COVID/' + '*.png'))\n",
    "opacity_images = sorted(glob.glob(path + 'Lung_Opacity/' + '*.png'))\n",
    "pneumonia_images = sorted(glob.glob(path+ 'Viral Pneumonia/' + '*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed) # python random seed 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # os 자체의 seed 고정\n",
    "    np.random.seed(seed) # numpy seed 고정 \n",
    "    torch.manual_seed(seed) # torch seed 고정\n",
    "    torch.cuda.manual_seed(seed) # cudnn seed 고정\n",
    "    torch.backends.cudnn.deterministic = True # cudnn seed 고정(nn.Conv2d)\n",
    "    torch.backends.cudnn.benchmark = False # CUDA 내부 연산에서 가장 빠른 알고리즘을 찾아 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "random_stat = 42\n",
    "seed_everything(random_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumonia_train_list , pneumonia_val_list = train_test_split(pneumonia_images, test_size=0.4, random_state=random_stat)\n",
    "pneumonia_val_list , pneumonia_test_list = train_test_split(pneumonia_val_list, test_size=0.5, random_state=random_stat)\n",
    "print(\"pneumonia_train_list :\" , len(pneumonia_train_list))\n",
    "print(\"pneumonia_val_list :\" , len(pneumonia_val_list))\n",
    "print(\"pneumonia_test_list :\" , len(pneumonia_test_list))\n",
    "print('-'*20)\n",
    "normal_train_list , normal_val_list = train_test_split(normal_images, test_size=0.4, random_state=random_stat)\n",
    "normal_val_list , normal_test_list = train_test_split(normal_val_list, test_size=0.5, random_state=random_stat)\n",
    "print(\"normal_train_list :\" , len(normal_train_list))\n",
    "print(\"normal_val_list :\" , len(normal_val_list))\n",
    "print(\"normal_test_list :\" , len(normal_test_list))\n",
    "print('-'*20)\n",
    "covid_train_list , covid_val_list = train_test_split(covid_images, test_size=0.4, random_state=random_stat)\n",
    "covid_val_list , covid_test_list = train_test_split(covid_val_list, test_size=0.5, random_state=random_stat)\n",
    "print(\"covid_train_list :\" , len(covid_train_list))\n",
    "print(\"covid_val_list :\" , len(covid_val_list))\n",
    "print(\"covid_test_list :\" , len(covid_test_list))\n",
    "print('-'*20)\n",
    "opacity_train_list , opacity_val_list = train_test_split(opacity_images, test_size=0.4, random_state=random_stat)\n",
    "opacity_val_list , opacity_test_list = train_test_split(opacity_val_list, test_size=0.5, random_state=random_stat)\n",
    "print(\"opacity_train_list :\" , len(opacity_train_list))\n",
    "print(\"opacity_val_list :\" , len(opacity_val_list))\n",
    "print(\"opacity_test_list :\" , len(opacity_test_list))\n",
    "print('-'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_train_list = normal_train_list + covid_train_list  + opacity_train_list + pneumonia_train_list\n",
    "# overall_val_list = normal_val_list + covid_val_list  + opacity_val_list + pneumonia_val_list\n",
    "# overall_test_list = normsal_test_list[:len(pneumonia_test_list)] + covid_test_list[:len(pneumonia_test_list)] + opacity_test_list[:len(pneumonia_test_list)] + pneumonia_test_list\n",
    "\n",
    "overall_train_list = normal_train_list[:len(pneumonia_test_list)] + covid_train_list[:len(pneumonia_test_list)] + opacity_train_list[:len(pneumonia_test_list)] + pneumonia_train_list[:len(pneumonia_test_list)]\n",
    "overall_val_list = normal_val_list[:len(pneumonia_test_list)] + covid_val_list[:len(pneumonia_test_list)] + opacity_val_list[:len(pneumonia_test_list)] + pneumonia_val_list[:len(pneumonia_test_list)]\n",
    "overall_test_list = normal_test_list[:len(pneumonia_test_list)] + covid_test_list[:len(pneumonia_test_list)] + opacity_test_list[:len(pneumonia_test_list)] +  pneumonia_test_list\n",
    "\n",
    "print(\"overall_train_list :\" , len(overall_train_list))\n",
    "print(\"overall_val_list :\" , len(overall_val_list))\n",
    "print(\"overall_test_list :\" , len(overall_test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U git+https://github.com/albumentations-team/albumentations --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "#feature generalization --> model 이 robust 하게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseaseDataset(Dataset):\n",
    "    def __init__(self ,phase_list, mode, image_size, aug, transform=None):\n",
    "        self.mode = mode \n",
    "        self.image_size = image_size\n",
    "        self.samples = phase_list\n",
    "        self.aug = aug\n",
    "        \n",
    "        if mode == 'train':\n",
    "            if self.aug == 'True':\n",
    "                self.transform = A.Compose([\n",
    "                    A.Resize(self.image_size, self.image_size),\n",
    "                    A.OneOf([\n",
    "                        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "                        A.MotionBlur(p=0.2),\n",
    "                        ], p=0.2),\n",
    "                    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=10, p=0.2),\n",
    "                    A.OneOf([\n",
    "                        A.OpticalDistortion(p=0.3),\n",
    "                        ], p=0.2),\n",
    "                    A.OneOf([\n",
    "                        A.GaussNoise(p=0.2),\n",
    "                        A.MultiplicativeNoise(p=0.2),\n",
    "                        ], p=0.2),\n",
    "                    A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=0, val_shift_limit=0.1, p=0.3),\n",
    "                    ToTensorV2(),\n",
    "                    ])\n",
    "            else:\n",
    "                self.transform = A.Compose([\n",
    "                    A.Resize(self.image_size, self.image_size),\n",
    "                    ToTensorV2(),\n",
    "                    ])\n",
    "        else:\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(self.image_size, self.image_size),\n",
    "                ToTensorV2(),\n",
    "                ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgs = self.transform(image=self._preprocessing(self.samples[idx]))['image']\n",
    "        if self.samples[idx].split('/')[-2] == 'Normal':\n",
    "            labels = 0\n",
    "        elif self.samples[idx].split('/')[-2] == 'COVID':\n",
    "            labels = 1\n",
    "        elif self.samples[idx].split('/')[-2] == 'Lung_Opacity':\n",
    "            labels = 2\n",
    "        else:\n",
    "            labels = 3\n",
    "        return imgs, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def _preprocessing(self, path):\n",
    "        img = cv2.imread(path).astype(np.float32)\n",
    "        img = self._min_max_scaling(img)\n",
    "        return img\n",
    "        \n",
    "    def _min_max_scaling(self, img):\n",
    "        return (img-np.min(img)) / (np.max(img)-np.min(img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=  256\n",
    "aug = True\n",
    "batch_size = 16\n",
    "w = 6\n",
    "\n",
    "train_datasets = DiseaseDataset(overall_train_list, mode='train', \n",
    "                                image_size=img_size, aug=aug)\n",
    "val_datasets = DiseaseDataset(overall_val_list, mode='test', \n",
    "                              image_size=img_size, aug=False)\n",
    "test_datasets = DiseaseDataset(overall_test_list, mode='test', \n",
    "                               image_size=img_size, aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_datasets, batch_size=batch_size, \n",
    "                                num_workers=w, pin_memory=True, \n",
    "                                shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_datasets, batch_size=batch_size, \n",
    "                                num_workers=w, pin_memory=True, \n",
    "                                shuffle=False, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_datasets, batch_size=1, \n",
    "                                num_workers=w, pin_memory=True, \n",
    "                                shuffle=False, drop_last=True)\n",
    "\n",
    "# shuffle , drop_last , pin_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet50(pretrained=False , num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary # keras와 다르게 torch는 기본 라이브러리에서 모델 구조를 가시화할 방법이 없습니다.\n",
    "\n",
    "summary(model, input_size=(3, 256, 256), device='cpu') # channel, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "print_freq = 30\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training 을 위한 tool입니다.\n",
    "class AverageMeter(object):\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    \n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install livelossplot --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses # 훈련하는 과정에서 동적으로 loss graph를 보여주게 하는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveloss = PlotLosses()\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, losses],\n",
    "        prefix='Epoch: [{}]'.format(epoch))\n",
    "    \n",
    "    model.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    end = time.time()\n",
    "    running_loss = 0\n",
    "    logs = {}\n",
    "    \n",
    "    for iter_, (imgs, labels) in enumerate(iter(train_loader)):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        loss = criterion(outputs, labels)\n",
    "        _, preds = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.update(loss.item(), imgs[0].size(0))\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (iter_ % print_freq == 0)& (iter_ != 0):\n",
    "            progress.display(iter_)\n",
    "    \n",
    "    logs['train' + ' loss'] = running_loss / len(train_loader)\n",
    "    logs['train' + '  acc'] = (100.*correct/total)\n",
    "    model.eval()\n",
    "    \n",
    "    val_batch_time = AverageMeter('Time', ':6.3f')\n",
    "    val_losses = AverageMeter('Loss', ':.4f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [val_batch_time, val_losses],\n",
    "        prefix='Epoch: [{}]'.format(epoch))\n",
    "    \n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_running_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for iter_, (imgs, labels) in enumerate(iter(val_loader)):\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += preds.eq(labels).sum().item()\n",
    "            \n",
    "            val_losses.update(loss.item(), imgs[0].size(0))\n",
    "            val_batch_time.update(time.time() - end)\n",
    "            val_running_loss += loss.item()\n",
    "            end = time.time()\n",
    "            \n",
    "            if (iter_ % print_freq == 0)& (iter_ != 0):\n",
    "                progress.display(iter_)\n",
    "    \n",
    "    logs['val' + ' loss'] = val_running_loss / len(val_loader)\n",
    "    logs['val' + '  acc'] = (100.*val_correct/val_total)\n",
    "    model.eval()\n",
    "    \n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "    \n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for iter_, (imgs, labels) in enumerate(iter(test_loader)):\n",
    "            imgs = imgs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            _, preds = outputs.max(1)\n",
    "\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += preds.eq(labels).sum().item()\n",
    "        \n",
    "    test_acc = 100.*test_correct/test_total\n",
    "    print('[*] Test Acc: {:5f}'.format(test_acc))\n",
    "    \n",
    "    model.train()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def show_confusion_matrix(cm, target_names, title='CFMatrix', cmap=None, normalize=False):\n",
    "        \n",
    "    acc = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - acc\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                    horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i,j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\n accuracy={:0.4f}'.format(acc))\n",
    "    \n",
    "def get_mertrix(gt, pred, class_list=['Normal', 'Abnormal']):\n",
    "    cnf_matrix = confusion_matrix(gt,pred)\n",
    "    FP = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)\n",
    "    FN = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
    "    TP = np.diag(cnf_matrix)\n",
    "    TN = cnf_matrix.sum() - (FP + FN + TP)\n",
    "    FP = FP.astype(float)\n",
    "    FN = FN.astype(float)\n",
    "    TP = TP.astype(float)\n",
    "    TN = TN.astype(float)\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    TPR = TP/(TP+FN)\n",
    "    # Specificity or true negative rate\n",
    "    TNR = TN/(TN+FP) \n",
    "    # Precision or positive predictive value\n",
    "    PPV = TP/(TP+FP)\n",
    "    # Negative predictive value\n",
    "    NPV = TN/(TN+FN)\n",
    "    # Fall out or false positive rate\n",
    "    FPR = FP/(FP+TN)\n",
    "    # False negative rate\n",
    "    FNR = FN/(TP+FN)\n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "    F1_Score = 2*(PPV*TPR) / (PPV+TPR)\n",
    "    # Overall accuracy for each class\n",
    "    ACC = (TP + TN)/ (TP+FP+FN+TN)\n",
    "\n",
    "\n",
    "    print('specificity: ', TNR) \n",
    "    print('sensitivity (recall): ', TPR) # true positive rate\n",
    "    print('positive predictive value (precision): ', PPV)\n",
    "    print('negative predictive value: ', NPV)\n",
    "    print('acc: ', ACC)\n",
    "    print('F1_score: ', F1_Score)\n",
    "    show_confusion_matrix(cnf_matrix, class_list)\n",
    "    \n",
    "    return cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['Normal', 'COVID', 'Lung Opacity' ,'Pneumonia']\n",
    "\n",
    "def evaluate(loader, model , class_list):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0    \n",
    "    overall_preds = []\n",
    "    overall_gts = []\n",
    "\n",
    "    for iter_, (imgs, labels) in tqdm.tqdm(enumerate(iter(loader))):\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = model(imgs)\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        _, preds = outputs.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        \n",
    "        ## For evaluation\n",
    "        overall_preds += preds.cpu().detach().numpy().tolist()\n",
    "        overall_gts += labels.cpu().detach().numpy().tolist()\n",
    "\n",
    "    print('[*] Test Acc: {:5f}'.format(100.*correct/total))          \n",
    "    return get_mertrix(overall_gts, overall_preds, class_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_loader, model.cuda() , class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Project-MONAI/MONAI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./MONAI')\n",
    "from monai.visualize import GradCAM\n",
    "from monai.visualize import CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cam(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    cnt = 0\n",
    "    \n",
    "    for iter_, (imgs, labels) in tqdm.tqdm(enumerate(iter(loader))):\n",
    "        if iter_ == 10:\n",
    "            break\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        pred_labels = model(imgs)\n",
    "        cam = GradCAM(nn_module = model, target_layers = 'layer3')\n",
    "        result = cam(x=imgs, layer_idx=-1)\n",
    "        result = result.squeeze().cpu().detach().numpy()\n",
    "        heatmap = np.uint8(255 * result)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        heatmap = heatmap/255\n",
    "\n",
    "        gt_imgs = imgs.cpu().detach().numpy().transpose(0,2,3,1)\n",
    "        cam_imgs = gt_imgs[0] \n",
    "        \n",
    "        pred_labels = F.softmax(pred_labels, dim=1)\n",
    "        \n",
    "        print(\"Class label 0 : Normal  , Class label 1 : COVID  , Class label 2 : Lung Opacity  , Class label 3 : Pneumonia \")\n",
    "        print(\"Labels is {} , pred_labels is {} \".format(labels.cpu().detach().numpy(),\n",
    "                                                         np.round(pred_labels.cpu().detach().numpy(), 4)))\n",
    "        print('-'*30)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(gt_imgs[0][:,:,0],'gray')\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(gt_imgs[0][:,:,0],'gray')\n",
    "        plt.imshow(heatmap , 'inferno', alpha=0.3)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cam(test_loader, model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiseaseDataset(Dataset):\n",
    "    def __init__(self ,phase_list, mode, image_size, aug, transform=None):\n",
    "        self.mode = mode \n",
    "        self.image_size = image_size\n",
    "        self.samples = phase_list\n",
    "        self.aug = aug\n",
    "        \n",
    "        if mode == 'train':\n",
    "            if self.aug == 'True':\n",
    "                self.transform = A.Compose([\n",
    "                    A.Resize(self.image_size, self.image_size),\n",
    "                    A.OneOf([\n",
    "                        A.MedianBlur(blur_limit=3, p=0.1),\n",
    "                        A.MotionBlur(p=0.2),\n",
    "                        ], p=0.2),\n",
    "                    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=10, p=0.2),\n",
    "                    A.OneOf([\n",
    "                        A.OpticalDistortion(p=0.3),\n",
    "                        ], p=0.2),\n",
    "                    A.OneOf([\n",
    "                        A.GaussNoise(p=0.2),\n",
    "                        A.MultiplicativeNoise(p=0.2),\n",
    "                        ], p=0.2),\n",
    "                    A.HueSaturationValue(hue_shift_limit=0, sat_shift_limit=0, val_shift_limit=0.1, p=0.3),\n",
    "                    A.Normalize(mean=(0.485), std=(0.229)),\n",
    "                    ToTensorV2(),\n",
    "                    ])\n",
    "            else:\n",
    "                self.transform = A.Compose([\n",
    "                    A.Resize(self.image_size, self.image_size),\n",
    "                    A.Normalize(mean=(0.485), std=(0.229)),\n",
    "                    ToTensorV2(),\n",
    "                    ])\n",
    "        else:\n",
    "            self.transform = A.Compose([\n",
    "                A.Resize(self.image_size, self.image_size),\n",
    "                A.Normalize(mean=(0.485), std=(0.229)),\n",
    "                ToTensorV2(),\n",
    "                ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        imgs = self.transform(image=self._preprocessing(self.samples[idx]))['image']\n",
    "        if self.samples[idx].split('/')[-2] == 'Normal':\n",
    "            labels = 0\n",
    "        elif self.samples[idx].split('/')[-2] == 'COVID':\n",
    "            labels = 1\n",
    "        elif self.samples[idx].split('/')[-2] == 'Lung_Opacity':\n",
    "            labels = 2\n",
    "        else:\n",
    "            labels = 3\n",
    "        return imgs, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def _preprocessing(self, path):\n",
    "        img = cv2.imread(path).astype(np.float32)\n",
    "        img = self._min_max_scaling(img)\n",
    "        return img\n",
    "    def _min_max_scaling(self, img):\n",
    "        return (img-np.min(img)) / (np.max(img)-np.min(img))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=  256\n",
    "aug = True\n",
    "batch_size = 16\n",
    "w = 6\n",
    "\n",
    "train_datasets = DiseaseDataset(overall_train_list, mode='train', \n",
    "                                image_size=img_size, aug=aug)\n",
    "val_datasets = DiseaseDataset(overall_val_list, mode='test', \n",
    "                              image_size=img_size, aug=False)\n",
    "test_datasets = DiseaseDataset(overall_test_list, mode='test', \n",
    "                               image_size=img_size, aug=False)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_datasets, batch_size=batch_size, \n",
    "                                num_workers=w, pin_memory=True, \n",
    "                                shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_datasets, batch_size=batch_size, \n",
    "                                num_workers=w, pin_memory=True, \n",
    "                                shuffle=False, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_datasets, batch_size=1, \n",
    "                                num_workers=w, pin_memory=True, \n",
    "                                shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('[*] build network...')\n",
    "resnet_model = models.resnet50(pretrained=False)\n",
    "resnet_model_pretrained = '/gdrive/MyDrive/moco_resnet50.pth.tar'\n",
    "\n",
    "if resnet_model_pretrained is not None:\n",
    "    if os.path.isfile(resnet_model_pretrained):\n",
    "        print(\"[*] loading checkpoint '{}'\".format(resnet_model_pretrained))\n",
    "        checkpoint = torch.load(resnet_model_pretrained, map_location=\"cpu\")\n",
    "\n",
    "        # rename moco pre-trained keys\n",
    "        state_dict = checkpoint['state_dict']\n",
    "        for k in list(state_dict.keys()):\n",
    "            # retain only encoder_q up to before the embedding layer\n",
    "            if k.startswith('module.encoder_q') and not k.startswith('module.encoder_q.fc'):\n",
    "                # remove prefix\n",
    "                state_dict[k[len(\"module.encoder_q.\"):]] = state_dict[k]\n",
    "            # delete renamed or unused k\n",
    "            del state_dict[k]\n",
    "\n",
    "        msg = resnet_model.load_state_dict(state_dict, strict=False)\n",
    "        assert set(msg.missing_keys) == {\"fc.weight\", \"fc.bias\"}\n",
    "\n",
    "        print(\"=> loaded pre-trained model '{}'\".format(resnet_model_pretrained))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resnet_model_pretrained))\n",
    "    print(\"[*] moco weight load completed\") \n",
    "\n",
    "\n",
    "model = resnet_model\n",
    "num_classes = 4\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "checkpoint = torch.load('/gdrive/MyDrive/fine_tuning_moco.pth.tar')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_loader, model.cuda() , class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cam(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    cnt = 0\n",
    "    img_mean = 0.485\n",
    "    img_std = 0.229\n",
    "    for iter_, (imgs, labels) in tqdm.tqdm(enumerate(iter(loader))):\n",
    "        if iter_ == 100:\n",
    "            break\n",
    "        imgs = imgs.cuda()\n",
    "        labels = labels.cuda()    \n",
    "        pred_labels = model(imgs)\n",
    "                \n",
    "        cam = GradCAM(nn_module = model, target_layers = 'layer3' )\n",
    "        result = cam(x=imgs, layer_idx=-1)\n",
    "        result = result.squeeze().cpu().detach().numpy()\n",
    "        \n",
    "        heatmap = np.uint8(255 * result)\n",
    "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "        heatmap = heatmap/255\n",
    "                \n",
    "        gt_imgs = imgs.cpu().detach().numpy().transpose(0,2,3,1)\n",
    "        gt_imgs = (gt_imgs*img_std)+img_mean\n",
    "        \n",
    "        cam_imgs = gt_imgs[0]\n",
    "        pred_labels = F.softmax(pred_labels, dim=1)\n",
    "        \n",
    "        print(\"Class label 0 : Normal  , Class label 1 : COVID  , Class label 2 : Lung Opacity  , Class label 3 : Pneumonia \")\n",
    "        print(\"Labels is {} , pred_labels is {} \".format(labels.cpu().detach().numpy(), np.round(pred_labels.cpu().detach().numpy(), 4)))\n",
    "        print('-'*30)\n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(gt_imgs[0][:,:,0],'gray')\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(gt_imgs[0][:,:,0],'gray')\n",
    "        plt.imshow(heatmap , 'inferno', alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_cam(test_loader,model.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
