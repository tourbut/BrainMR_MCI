{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import pandas as pd\n",
    "import utils\n",
    "from model import generate_model\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from optimizer import Adam,SGD\n",
    "\n",
    "from train_wrapper import train_epoch\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_config()\n",
    "\n",
    "batch_size = config['dataloader']['batch_size']\n",
    "num_workers = config['dataloader']['num_workers']\n",
    "pin_memory = config['dataloader']['pin_memory'] == 1 \n",
    "gpu_parallel = config['gpus']\n",
    "learning_rate = config['train']['learning_rate']\n",
    "lr_steps = config['train']['lr_steps']\n",
    "epochs = config['train']['epochs']\n",
    "\n",
    "config['save_datetime'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 분리(Train, validation, test)\n",
    "df_dataset = pd.read_csv(config['PATH_DATASET_CSV'])\n",
    "df_dataset = df_dataset.dropna().reset_index(drop=True)\n",
    "df_oasis = df_dataset[df_dataset['source'] == 'OASIS-3']\n",
    "df_adni = df_dataset[df_dataset['source'] == 'ADNI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data\n",
      " Total: 990    CN : 576 (58.18% of total),   MCI: 263 (26.57% of total),   AD : 151 (15.25% of total)\n",
      "Oasis Data\n",
      " Total: 824    CN : 524 (63.59% of total),   MCI: 183 (22.21% of total),   AD : 117 (14.20% of total)\n",
      "ADNI Data\n",
      " Total: 166    CN : 52 (31.33% of total),   MCI: 80 (48.19% of total),   AD : 34 (20.48% of total)\n"
     ]
    }
   ],
   "source": [
    "#데이터 분포도 확인 \n",
    "data_summary=''\n",
    "raw_ad,raw_cn,raw_mci = pd.get_dummies(df_dataset['group_maxinc']).sum()\n",
    "\n",
    "raw_total = raw_ad + raw_cn + raw_mci\n",
    "data_summary = 'Raw Data\\n Total: {}    CN : {} ({:.2f}% of total),   MCI: {} ({:.2f}% of total),   AD : {} ({:.2f}% of total)'.format(raw_total, raw_cn,  100 * raw_cn / raw_total, raw_mci, 100 * raw_mci / raw_total, raw_ad,  100 * raw_ad / raw_total)\n",
    "\n",
    "oasis_ad,oasis_cn,oasis_mci = pd.get_dummies(df_oasis['group_maxinc']).sum()\n",
    "\n",
    "oasis_total = oasis_ad + oasis_cn + oasis_mci\n",
    "data_summary += '\\nOasis Data\\n Total: {}    CN : {} ({:.2f}% of total),   MCI: {} ({:.2f}% of total),   AD : {} ({:.2f}% of total)'.format(oasis_total, oasis_cn,  100 * oasis_cn / oasis_total, oasis_mci, 100 * oasis_mci / oasis_total, oasis_ad,  100 * oasis_ad / oasis_total)\n",
    "\n",
    "adni_ad,adni_cn,adni_mci = pd.get_dummies(df_adni['group_maxinc']).sum()\n",
    "adni_total = adni_ad + adni_cn + adni_mci\n",
    "data_summary += '\\nADNI Data\\n Total: {}    CN : {} ({:.2f}% of total),   MCI: {} ({:.2f}% of total),   AD : {} ({:.2f}% of total)'.format(adni_total, adni_cn,  100 * adni_cn / adni_total, adni_mci, 100 * adni_mci / adni_total, adni_ad,  100 * adni_ad / adni_total)\n",
    "\n",
    "print(data_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGit\\BrainMR_MCI\\dataloader.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset['grp'] = (df_dataset['source'].str.replace('OASIS-3','1').str.replace('ADNI','2').apply(pd.to_numeric)*1000\n"
     ]
    }
   ],
   "source": [
    "X_train,X_val,y_train,y_val = dataloader.dataset_split(df_oasis,test_size=0.2,shuffle=True,grp=None,seed=1004)\n",
    "X_test = df_adni.drop(labels='group_maxinc',axis=1)\n",
    "y_test = df_adni['group_maxinc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader :  659\n",
      "val_dataloader :  165\n",
      "test_dataloader :  166\n"
     ]
    }
   ],
   "source": [
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader,ConcatDataset,WeightedRandomSampler\n",
    "\n",
    "class_counts = y_train.value_counts().to_dict() \n",
    "num_samples = sum(class_counts.values()) \n",
    "labels = y_train.to_list()\n",
    "\n",
    "#클래스별 가중치 부여\n",
    "class_weights = {i:num_samples / class_counts[i] for i in class_counts.keys()}\n",
    "\n",
    "# 해당 데이터의 label에 해당되는 가중치\n",
    "weights = [class_weights[labels[i]] for i in range(int(num_samples))] #해당 레이블마다의 가중치 비율\n",
    "\n",
    "sampler = WeightedRandomSampler(torch.DoubleTensor(weights), int(num_samples))\n",
    "\n",
    "transform = tio.RandomAffine(degrees=(0,0,90)) #이미지 좌우로 랜덤 생성\n",
    "\n",
    "traindata=dataloader.MRIDataset_class2(X_train,y_train)\n",
    "#aug_traindata=dataloader.MRIDataset(X_train,y_train,transform)\n",
    "\n",
    "#train_plus = ConcatDataset([traindata, aug_traindata])\n",
    "\n",
    "valdata=dataloader.MRIDataset_class2(X_val,y_val)\n",
    "testdata=dataloader.MRIDataset_class2(X_test,y_test)\n",
    "\n",
    "shuffle = True\n",
    "sampler = None\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(traindata , batch_size=batch_size, shuffle=shuffle, sampler = sampler\n",
    "                              ,num_workers=num_workers,pin_memory = pin_memory)\n",
    "val_dataloader  = DataLoader(valdata, batch_size=batch_size, shuffle=False\n",
    "                              ,num_workers=num_workers,pin_memory = pin_memory)\n",
    "test_dataloader  = DataLoader(testdata, batch_size=1, shuffle=False)\n",
    "\n",
    "print('train_dataloader : ',len(train_dataloader.dataset))\n",
    "print('val_dataloader : ',len(val_dataloader.dataset))\n",
    "print('test_dataloader : ',len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = []\n",
    "for w in class_weights.values():\n",
    "    loss_weights.append(w)\n",
    "    \n",
    "loss_weights = torch.tensor(loss_weights,dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGit\\BrainMR_MCI\\models\\resnet.py:143: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 0\n",
      "Epoch: [0][0/165]\t lr: 0.0900000000\tLoss : 1.0235\tAcc : 0.25000\t\n",
      "Epoch: [0][10/165]\t lr: 0.0900000000\tLoss : 7.4284\tAcc : 0.54545\t\n",
      "Epoch: [0][20/165]\t lr: 0.0900000000\tLoss : 4.2453\tAcc : 0.54762\t\n",
      "Epoch: [0][30/165]\t lr: 0.0900000000\tLoss : 3.0796\tAcc : 0.60484\t\n",
      "Epoch: [0][40/165]\t lr: 0.0900000000\tLoss : 2.5063\tAcc : 0.59756\t\n",
      "Epoch: [0][50/165]\t lr: 0.0900000000\tLoss : 2.1398\tAcc : 0.61275\t\n",
      "Epoch: [0][60/165]\t lr: 0.0900000000\tLoss : 1.8926\tAcc : 0.62295\t\n",
      "Epoch: [0][70/165]\t lr: 0.0900000000\tLoss : 1.7269\tAcc : 0.61268\t\n",
      "Epoch: [0][80/165]\t lr: 0.0900000000\tLoss : 1.5910\tAcc : 0.62346\t\n",
      "Epoch: [0][90/165]\t lr: 0.0900000000\tLoss : 1.4715\tAcc : 0.64286\t\n",
      "Epoch: [0][100/165]\t lr: 0.0900000000\tLoss : 1.3796\tAcc : 0.65594\t\n",
      "Epoch: [0][110/165]\t lr: 0.0900000000\tLoss : 1.3207\tAcc : 0.65315\t\n",
      "Epoch: [0][120/165]\t lr: 0.0900000000\tLoss : 1.2650\tAcc : 0.65496\t\n",
      "Epoch: [0][130/165]\t lr: 0.0900000000\tLoss : 1.2231\tAcc : 0.64695\t\n",
      "Epoch: [0][140/165]\t lr: 0.0900000000\tLoss : 1.1849\tAcc : 0.64007\t\n",
      "Epoch: [0][150/165]\t lr: 0.0900000000\tLoss : 1.1503\tAcc : 0.63907\t\n",
      "Epoch: [0][160/165]\t lr: 0.0900000000\tLoss : 1.1207\tAcc : 0.63665\t\n",
      "Epoch: [0][164/165]\t lr: 0.0900000000\tLoss : 1.1115\tAcc : 0.63429\t\n",
      "valid at epoch 0\n",
      "Epoch: [0][0/42]\t Loss : 0.4533\tAcc : 1.00000\t\n",
      "Epoch: [0][10/42]\t Loss : 0.6389\tAcc : 0.65909\t\n",
      "Epoch: [0][20/42]\t Loss : 0.6445\tAcc : 0.64286\t\n",
      "Epoch: [0][30/42]\t Loss : 0.6610\tAcc : 0.61290\t\n",
      "Epoch: [0][40/42]\t Loss : 0.6464\tAcc : 0.64024\t\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 24\u001b[0m\n\u001b[0;32m     16\u001b[0m criterion_clf \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     18\u001b[0m utils\u001b[38;5;241m.\u001b[39msave_messgage(config\n\u001b[0;32m     19\u001b[0m                     , model_name\u001b[38;5;241m=\u001b[39mmodel_name, model_depth \u001b[38;5;241m=\u001b[39m model_depth, n_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, resnet_shortcut\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     20\u001b[0m                     , optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, lr\u001b[38;5;241m=\u001b[39mlearning_rate, criterion_clf\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrossEntropyLoss\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m                     , data_summary\u001b[38;5;241m=\u001b[39mdata_summary, sampler\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m, agumentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mN\u001b[39m\u001b[38;5;124m'\u001b[39m,add_last_fc_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     22\u001b[0m                     , class_weights \u001b[38;5;241m=\u001b[39mclass_weights\n\u001b[0;32m     23\u001b[0m                     , message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m비고\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion_clf\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mage_onoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\MyGit\\BrainMR_MCI\\train_wrapper.py:30\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(device, train_dataloader, valid_dataloader, test_dataloader, model, criterion_clf, optimizer, config, epoch, age_onoff, num_classes)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m     24\u001b[0m     \n\u001b[0;32m     25\u001b[0m     \u001b[39m#adjust_learning_rate(optimizer,i,learning_rate,lr_steps=lr_steps)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m     loss, acc \u001b[39m=\u001b[39m train(device,i,train_dataloader,model,criterion_clf\n\u001b[0;32m     28\u001b[0m                     ,optimizer,train_logger,train_batch_logger,age_onoff\u001b[39m=\u001b[39mage_onoff)\n\u001b[1;32m---> 30\u001b[0m     val_loss,val_acc \u001b[39m=\u001b[39m validation(device,i,valid_dataloader,model,criterion_clf,valid_logger,age_onoff\u001b[39m=\u001b[39;49mage_onoff,num_classes\u001b[39m=\u001b[39;49mnum_classes)\n\u001b[0;32m     33\u001b[0m     \u001b[39m#성능이 향상이 없을 때 learning rate를 감소시킨다\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(val_acc)\n",
      "File \u001b[1;32md:\\MyGit\\BrainMR_MCI\\validation.py:69\u001b[0m, in \u001b[0;36mvalidation\u001b[1;34m(device, epoch, data_loader, model, criterion, logger, age_onoff, num_classes)\u001b[0m\n\u001b[0;32m     67\u001b[0m _thresholds \u001b[39m=\u001b[39m []\n\u001b[0;32m     68\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m3\u001b[39m):\n\u001b[1;32m---> 69\u001b[0m     _fpr\u001b[39m.\u001b[39mappend(fpr[i]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m     70\u001b[0m     _tpr\u001b[39m.\u001b[39mappend(tpr[i]\u001b[39m.\u001b[39mtolist())\n\u001b[0;32m     71\u001b[0m     _thresholds\u001b[39m.\u001b[39mappend(thresholds[i]\u001b[39m.\u001b[39mtolist())\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#case 1: epoch=100, add age = 'N',밸런스 조정 ='N',Crop: (가로,세로,깊이), normalize=minmax(5,95)\n",
    "config['save_datetime'] = datetime.datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "model_name = 'resnet'\n",
    "model_depth = 18\n",
    "\n",
    "model, _ = generate_model(model_name=model_name,model_depth = model_depth\n",
    "                        ,n_classes=2,resnet_shortcut='B',add_last_fc_num=0)\n",
    "model.to(device)\n",
    "\n",
    "if len(gpu_parallel) > 1 and torch.cuda.is_available():\n",
    "    model = nn.DataParallel(model, device_ids = gpu_parallel)\n",
    "    model.to(device)\n",
    "\n",
    "optimizer = Adam(model, learning_rate = learning_rate)\n",
    "criterion_clf = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "utils.save_messgage(config\n",
    "                    , model_name=model_name, model_depth = model_depth, n_classes=3, resnet_shortcut='B'\n",
    "                    , optimizer = 'Adam', lr=learning_rate, criterion_clf='CrossEntropyLoss'\n",
    "                    , data_summary=data_summary, sampler= 'N', agumentation='N',add_last_fc_num=0\n",
    "                    , class_weights =class_weights\n",
    "                    , message='비고')\n",
    "train_epoch(device,train_dataloader,val_dataloader,test_dataloader,model,criterion_clf,optimizer,config,epoch = epochs,age_onoff=True,num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('pymain': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ed8220e6a4d179c92912ea3d00b50a7e26f85dad7a0d0d921d007db80c03c33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
