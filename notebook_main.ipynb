{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "import pandas as pd\n",
    "import utils\n",
    "from model import generate_model\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from optimizer import Adam,SGD\n",
    "\n",
    "from train_wrapper import train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_config()\n",
    "\n",
    "batch_size = config['dataloader']['batch_size']\n",
    "num_workers = config['dataloader']['num_workers']\n",
    "pin_memory = config['dataloader']['pin_memory'] == 1 \n",
    "gpu_parallel = config['gpus']\n",
    "learning_rate = config['train']['learning_rate']\n",
    "lr_steps = config['train']['lr_steps']\n",
    "epochs = config['train']['epochs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGit\\BrainMR_MCI\\dataloader.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_dataset['grp'] = (df_dataset['source'].str.replace('OASIS-3','1').str.replace('ADNI','2').apply(pd.to_numeric)*1000\n"
     ]
    }
   ],
   "source": [
    "#데이터셋 분리(Train, validation, test)\n",
    "df_dataset = pd.read_csv(config['PATH_DATASET_CSV'])\n",
    "df_dataset = df_dataset.dropna().reset_index(drop=True)\n",
    "df_oasis = df_dataset[df_dataset['source'] == 'OASIS-3']\n",
    "df_adni = df_dataset[df_dataset['source'] == 'ADNI']\n",
    "X_train,X_val,y_train,y_val = dataloader.dataset_split(df_oasis,test_size=0.2,shuffle=True,grp=None,seed=1004)\n",
    "X_test = df_adni.drop(labels='group_maxinc',axis=1)\n",
    "y_test = df_adni['group_maxinc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataloader :  659\n",
      "val_dataloader :  165\n",
      "test_dataloader :  166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGit\\BrainMR_MCI\\pymain\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:554: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "traindata=dataloader.MRIDataset(X_train,y_train)\n",
    "valdata=dataloader.MRIDataset(X_val,y_val)\n",
    "testdata=dataloader.MRIDataset(X_test,y_test)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(traindata, batch_size=batch_size, shuffle=True\n",
    "                              ,num_workers=num_workers,pin_memory = pin_memory)\n",
    "val_dataloader  = DataLoader(valdata, batch_size=batch_size, shuffle=False\n",
    "                              ,num_workers=num_workers,pin_memory = pin_memory)\n",
    "test_dataloader  = DataLoader(testdata, batch_size=1, shuffle=False)\n",
    "\n",
    "print('train_dataloader : ',len(train_dataloader.dataset))\n",
    "print('val_dataloader : ',len(val_dataloader.dataset))\n",
    "print('test_dataloader : ',len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MyGit\\BrainMR_MCI\\models\\resnet.py:140: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  m.weight = nn.init.kaiming_normal(m.weight, mode='fan_out')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model_name = config['model']['model_name']\n",
    "model_depth = config['model']['model_depth']\n",
    "\n",
    "model, _ = generate_model(model_name=model_name,model_depth = model_depth,n_classes=3,resnet_shortcut='B')\n",
    "model.to(device)\n",
    "\n",
    "if len(gpu_parallel) > 1 and torch.cuda.is_available():\n",
    "    model = nn.DataParallel(model, device_ids = gpu_parallel)\n",
    "    model.to(device)\n",
    "\n",
    "optimizer = Adam(model, learning_rate= learning_rate)\n",
    "criterion_clf = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train at epoch 0\n"
     ]
    }
   ],
   "source": [
    "train_epoch(device,train_dataloader,val_dataloader,model,criterion_clf,optimizer,config\n",
    "            ,epoch=epochs,learning_rate= learning_rate,lr_steps=lr_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('pymain': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ed8220e6a4d179c92912ea3d00b50a7e26f85dad7a0d0d921d007db80c03c33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
